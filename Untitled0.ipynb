{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lanwei02/Bitcoin-MarketPrice-Prediction/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYxGpCD-SKxI"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "pd.set_option('max_colwidth', 500)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xeIv89jbsl1",
        "outputId": "ab9bfcd8-1c13-469f-8a24-89a8d418dc47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "!pip install transformers bert torch"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: bert in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: erlastic in /usr/local/lib/python3.6/dist-packages (from bert) (2.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qubbusG0SNf-",
        "outputId": "21609eb7-c3e1-4d5f-b37b-829195fb46fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Setup root directory\n",
        "GET_DATA_FROM_COLAB=True\n",
        "if GET_DATA_FROM_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive', force_remount=True)\n",
        "  root_path = '/content/gdrive/My Drive/Geekon2020' \n",
        "else: # Local machine\n",
        "    root_path ='' # e.g., root_path = '/Users/shxu/Documents/hack2020/'\n",
        "os.chdir(root_path)\n",
        "!pwd"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Geekon2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u55mFLxmTmvd"
      },
      "source": [
        "senti_data = pd.read_csv('sentiment_hbw.csv',\n",
        "                         names = ['deal_uuid', 'permalink', 'grt_l1_cat_name', 'grt_l2_cat_name', 'grt_l3_cat_name', 'grt_l4_cat_name',\n",
        "                     'pds_cat_name', 'review', 'dwh_updated_at', 'int_value', 'sentiment_type', 'sentiment_score','user_id', 'client_platform'],\n",
        "                         delimiter='\\t', index_col=False,\n",
        "                         na_values = ['NA', 'N/A', '\\\\N'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KkaiDDIUEyS"
      },
      "source": [
        "# senti_data.head(2)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83LqwPLpWMCD"
      },
      "source": [
        "## *PreProcessing*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iShONghOWOU7"
      },
      "source": [
        "def preprocessing(data):\n",
        "\n",
        "  # Rename\n",
        "  data.rename(columns = {'int_value': 'star_rating', 'dwh_updated_at': 'update_timestamp'}, inplace = True)\n",
        "  \n",
        "  # Drop NULL Label\n",
        "  data = data[~data['star_rating'].isna()]\n",
        "\n",
        "  # Drop 0 star rating deals\n",
        "  data = data[data['star_rating']>0]\n",
        "\n",
        "  # Correct data type\n",
        "  data['update_timestamp'] = pd.to_datetime(data['update_timestamp'])\n",
        "  data['star_rating'] = data['star_rating'].astype(object)\n",
        "\n",
        "  # Impute NULL review with empty string\n",
        "  data['review'].fillna('', inplace = True)\n",
        "\n",
        "\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "senti_data_c = senti_data.copy()\n",
        "senti_data_c = preprocessing(senti_data_c)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQWrrCDFdjZC",
        "outputId": "b4f0ec40-44cf-46ff-a885-95b5201cc17c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "senti_data_c[senti_data_c['sentiment_type'].isnull()]['star_rating'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0    972\n",
              "4.0     94\n",
              "3.0     30\n",
              "1.0     26\n",
              "2.0     14\n",
              "Name: star_rating, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-tDNHxrdQ2Y"
      },
      "source": [
        "# senti_data_c[senti_data_c['sentiment_type'].isnull()]['review'].unique()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qZDgwNeavB5"
      },
      "source": [
        "# senti_data_c['sentiment_type'].unique()[3]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f09b4qcOk_0s"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nst3MOh8WrRd"
      },
      "source": [
        "# acc_df = pd.DataFrame(senti_data_c[['star_rating', 'sentiment_type']].value_counts()).rename(columns={0: 'count'}).reset_index()\n",
        "# acc_df['pct'] = acc_df['count']/acc_df['count'].sum()\n",
        "# acc_df['star_rating_sentiment'] = acc_df['star_rating'].map(lambda x: 'positive' if x >=4 else ('negative' if x <= 2 else 'neutral'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GRaK1CbhNQc"
      },
      "source": [
        "# acc_df.sort_values(by=['star_rating_sentiment', 'sentiment_type'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp0vkehRhcZU"
      },
      "source": [
        "# acc_df[acc_df['sentiment_type'] == acc_df['star_rating_sentiment']]['pct'].sum()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuWdEbqpjvvN"
      },
      "source": [
        "# acc_df.to_csv('prevous_accuracy.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWS43nEhj-vl"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZKufLAdvKaK"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPKbnK77mtWV"
      },
      "source": [
        "### Fine-Tuning BERT for Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-sHZXkivLze"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = senti_data_c['review'].values\n",
        "y = senti_data_c['star_rating'].values\n",
        "\n",
        "# 70% train, 20% validation, 10% test\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=2020, stratify = y)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HRMtARQvR9S"
      },
      "source": [
        "X = X_val\n",
        "y = y_val\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=0.333, random_state=2020, stratify = y)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHMkx9OfYwlX"
      },
      "source": [
        "df_train = pd.DataFrame({'review': X_train, 'star_rating': y_train}, columns=['review', 'star_rating'])\n",
        "df_val = pd.DataFrame({'review': X_val, 'star_rating': y_val}, columns=['review', 'star_rating'])\n",
        "df_test = pd.DataFrame({'review': X_test, 'star_rating': y_test}, columns=['review', 'star_rating'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm9rIkuZvRVg"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "import torch"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vCKMUbO-iz8"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su5JFIXqac51"
      },
      "source": [
        "config = {\n",
        "    \"splitRatio\" : 0.8,\n",
        "    \"maxLength\" : 100,\n",
        "    \"printEvery\" : 5,\n",
        "    \"outputFolder\" : \"Models\",\n",
        "    \"outputFileName\" : \"AmazonReviewClassifier.dat\",\n",
        "    \"threads\" : 4,\n",
        "    \"batchSize\" : 64,\n",
        "    \"validationFraction\" : 0.0005,\n",
        "    \"epochs\" : 1,\n",
        "    \"forceCPU\" : False\n",
        "    }"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAMUSrQ4mUaC"
      },
      "source": [
        "df = pd.concat([df_train, df_val])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOTn5GQwfHtZ",
        "outputId": "f1f58b44-132d-4c4f-ef5b-d5b86c3314e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_classes = df['star_rating'].nunique()\n",
        "print(\"Number of Target Output Classes:\", num_classes)\n",
        "totalDatasetSize = len(df)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Target Output Classes: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtHyCHzYozdz"
      },
      "source": [
        "# Group by the column Score. This helps you get distribution of the Review Scores.\n",
        "symbols = df.groupby('star_rating')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbIaGoNeo7RM"
      },
      "source": [
        "scores_dist = []\n",
        "for i in range(num_classes):\n",
        "  scores_dist.append(len(symbols.groups[i+1])/totalDatasetSize)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgVdWOwBpIul",
        "outputId": "de29b0f0-6f23-4825-8985-796c43bdef17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "scores_dist"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05628078761718057,\n",
              " 0.02052280387349729,\n",
              " 0.026451765497855384,\n",
              " 0.05361537027013504,\n",
              " 0.8431292727413318]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGwl80FOeSQ9",
        "outputId": "96a06bde-f6ed-4592-a14c-91fbc5b22243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Set GPU for Training\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    config[\"device\"] = device\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZHYIukYefaG"
      },
      "source": [
        "# print('Loading BERT tokenizer...')\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-tG5Xk2vWYy"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, df, maxlen):\n",
        "        self.df = df\n",
        "        # self.df_x = df_x\n",
        "        # self.df_y = df_y\n",
        "        # A reset reindexes from 1 to len(df), the shuffled df frames are sparse.\n",
        "        # self.df.reset_index(drop=True, inplace=True)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return(len(self.df))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        review = self.df.loc[index, 'review']\n",
        "        # review = self.df_x.loc[index]\n",
        "\n",
        "        # Classes start from 0.\n",
        "        # label = int(self.df.loc[index, 'Score']) - 1\n",
        "        # label = int(self.df_y.loc[index]) - 1\n",
        "        label = int(self.df.loc[index, 'star_rating']) - 1\n",
        "\n",
        "        # Use BERT tokenizer since it needs to be able to match the tokens to the pre trained words.\n",
        "        tokens = self.tokenizer.tokenize(review)\n",
        "\n",
        "        # BERT inputs typically start with a '[CLS]' tag and end with a '[SEP]' tag. For\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "\n",
        "        if len(tokens) < self.maxlen:\n",
        "            # Add the ['PAD'] token\n",
        "            tokens = tokens + ['[PAD]' for item in range(self.maxlen-len(tokens))]\n",
        "        else:\n",
        "            # Truncate the tokens at maxLen - 1 and add a '[SEP]' tag.\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]']\n",
        "\n",
        "        # BERT tokenizer converts the string tokens to their respective IDs.\n",
        "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # Converting to pytorch tensors.\n",
        "        tokens_ids_tensor = torch.tensor(token_ids)\n",
        "\n",
        "        # Masks place a 1 if token != PAD else a 0.\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHOiGAJm8AzB"
      },
      "source": [
        "train_set = ReviewsDataset(df_train, maxlen = config['maxLength'])\n",
        "val_set = ReviewsDataset(df_val, maxlen = config['maxLength'])\n",
        "test_set = ReviewsDataset(df_test, maxlen = config['maxLength'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qd20lFKUBZH"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBS8hurk-pxX"
      },
      "source": [
        "train_loader = DataLoader(train_set, batch_size = config[\"batchSize\"], num_workers = config[\"threads\"])\n",
        "val_loader = DataLoader(val_set, batch_size = config[\"batchSize\"], num_workers = config[\"threads\"])\n",
        "test_loader = DataLoader(test_set, batch_size = config[\"batchSize\"], num_workers = config[\"threads\"])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiGnvjlre4qJ"
      },
      "source": [
        "### Define the Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QQnXSSn-p68"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import  BertModel, BertTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, num_classes, freeze_bert = True):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "        # self.device = device\n",
        "\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        self.cls_layer = nn.Linear(768, num_classes)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "        '''\n",
        "\n",
        "        #Feeding the input to BERT model to obtain contextualized representations\n",
        "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
        "\n",
        "        #Obtaining the representation of [CLS] head\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "\n",
        "        #Feeding cls_rep to the classifier layer\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits.cuda()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgBkK2mKghgj",
        "outputId": "986c5456-1265-409f-d221-01a640c3631b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config[\"device\"] "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bgb5iPVZRu1"
      },
      "source": [
        "# .cuda()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugs6dEUR-p90"
      },
      "source": [
        "# We are unfreezing the BERT layers so as to be able to fine tune and save a new BERT model that is specific to the reviews dataset.\n",
        "net = SentimentClassifier(num_classes, freeze_bert=False)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95QcoMhu-p_m"
      },
      "source": [
        "net = net.cuda()\n",
        "weights = torch.tensor(scores_dist).cuda()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYfTy3IF-qCV"
      },
      "source": [
        "# Setting the Loss function and Optimizer.\n",
        "loss_func = nn.NLLLoss(weight=weights)\n",
        "opti = optim.Adam(net.parameters(), lr = 2e-5)\n",
        "m = nn.LogSoftmax(dim=1)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YulVQNs4qCph"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL6jMv1wb91m"
      },
      "source": [
        "def read_and_shuffle(file):\n",
        "    df = pd.read_csv(file, delimiter=',')\n",
        "    # Random shuffle.\n",
        "    df.sample(frac=1)\n",
        "    return df\n",
        "\n",
        "def get_train_and_val_split(df, splitRatio=0.8):\n",
        "    train=df.sample(frac=splitRatio,random_state=200)\n",
        "    val=df.drop(train.index)\n",
        "    print(\"Number of Training Samples: \", len(train))\n",
        "    print(\"Number of Validation Samples: \", len(val))\n",
        "    return(train, val)\n",
        "\n",
        "def get_max_length(reviews):\n",
        "    return len(max(reviews, key=len))\n",
        "\n",
        "def get_accuracy(logits, labels):\n",
        "    # get the index of the max value in the row.\n",
        "    predictedClass = logits.max(dim = 1)[1]\n",
        "\n",
        "    # get accuracy by averaging over entire batch.\n",
        "    acc = (predictedClass == labels).float().mean()\n",
        "    return acc\n",
        "\n",
        "def trainFunc(net, loss_func, opti, train_loader, test_loader, config):\n",
        "    best_acc = 0\n",
        "    for ep in range(config[\"epochs\"]):\n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            opti.zero_grad()\n",
        "            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
        "\n",
        "            logits = net(seq, attn_masks)\n",
        "            loss = loss_func(m(logits), labels)\n",
        "\n",
        "            loss.backward()\n",
        "            opti.step()\n",
        "            print(\"Iteration: \", it+1)\n",
        "\n",
        "            if (it + 1) % config[\"printEvery\"] == 0:\n",
        "                acc = get_accuracy(m(logits), labels)\n",
        "                if not os.path.exists(config[\"outputFolder\"]):\n",
        "                    os.makedirs(config[\"outputFolder\"])\n",
        "\n",
        "                # Since a single epoch could take well over hours, we regularly save the model even during evaluation of training accuracy.\n",
        "                torch.save(net.state_dict(), os.path.join(config[\"outputFolder\"], config[\"outputFileName\"]))\n",
        "                print(\"Iteration {} of epoch {} complete. Loss : {} Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
        "\n",
        "        # perform validation at the end of an epoch.\n",
        "        val_acc, val_loss = evaluate(net, loss_func, val_loader, config)\n",
        "        print(\" Validation Accuracy : {}, Validation Loss : {}\".format(val_acc, val_loss))\n",
        "        if val_acc > best_acc:\n",
        "            print(\"Best validation accuracy improved from {} to {}, saving model...\".format(best_acc, val_acc))\n",
        "            best_acc = val_acc\n",
        "            torch.save(net.state_dict(), os.path.join(config[\"outputFolder\"], config[\"outputFileName\"] + \"_valTested_\" + str(best_acc)))\n",
        "\n",
        "def evaluate(net, loss_func, dataloader, config):\n",
        "    net.eval()\n",
        "\n",
        "    mean_acc, mean_loss = 0, 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for seq, attn_masks, labels in dataloader:\n",
        "            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
        "\n",
        "            logits = net(seq, attn_masks)\n",
        "            mean_loss += loss_func(m(logits), labels)\n",
        "            mean_acc += get_accuracy(m(logits), labels)\n",
        "            print(\"Validation iteration\", count+1)\n",
        "            count += 1\n",
        "\n",
        "            '''\n",
        "            The entire validation set was around 0.1 million entries,\n",
        "            the validationFraction param controls what fraction of the shuffled\n",
        "            validation set you want to validate the results on.\n",
        "            '''\n",
        "            if count > config[\"validationFraction\"] * len(val_set):\n",
        "                break\n",
        "\n",
        "    return mean_acc / count, mean_loss / count"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2GhdPZcRBv2"
      },
      "source": [
        "net.bert_layer.to(config['device'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLHibAH6OCLC",
        "outputId": "0188cafa-9358-4cdf-e559-f4873c4968b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# net, loss_func, opti, train_loader, test_loader, config\n",
        "\n",
        "if not os.path.exists(config[\"outputFolder\"]):\n",
        "  os.makedirs(config[\"outputFolder\"])\n",
        "\n",
        "best_acc = 0\n",
        "for ep in range(config[\"epochs\"]):\n",
        "    for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "        # seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "        seq, attn_masks, labels = seq.to(config[\"device\"]), attn_masks.to(config[\"device\"]), labels.to(config[\"device\"])\n",
        "        opti.zero_grad()\n",
        "\n",
        "        logits = net(seq, attn_masks)\n",
        "        loss = loss_func(m(logits), labels)\n",
        "\n",
        "        loss.backward()\n",
        "        opti.step()\n",
        "        print(\"Iteration: \", it+1)\n",
        "\n",
        "        if (it + 1) % config[\"printEvery\"] == 0:\n",
        "            acc = get_accuracy(m(logits), labels)\n",
        "\n",
        "            # Since a single epoch could take well over hours, we regularly save the model even during evaluation of training accuracy.\n",
        "            torch.save(net.state_dict(), os.path.join(config[\"outputFolder\"], config[\"outputFileName\"]))\n",
        "            print(\"Iteration {} of epoch {} complete. Loss : {} Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
        "\n",
        "    # perform validation at the end of an epoch.\n",
        "    # iteration time - len(train_loader)\n",
        "    val_acc, val_loss = evaluate(net, loss_func, val_loader, config)\n",
        "    print(\" Validation Accuracy : {}, Validation Loss : {}\".format(val_acc, val_loss))\n",
        "    if val_acc > best_acc:\n",
        "        print(\"Best validation accuracy improved from {} to {}, saving model...\".format(best_acc, val_acc))\n",
        "        best_acc = val_acc\n",
        "        torch.save(net.state_dict(), os.path.join(config[\"outputFolder\"], config[\"outputFileName\"] + \"_valTested_\" + str(best_acc)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d159cdc9e66e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# net, loss_func, opti, train_loader, test_loader, config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputFolder\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputFolder\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h98WDpJSpZX"
      },
      "source": [
        "net.bert_layer.to(config['device'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zx_hBz9TE-C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWlEDyK_SqCG"
      },
      "source": [
        "net = net.cuda()\n",
        "seq = seq.cuda()\n",
        "attn_masks = attn_masks.cuda()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKmGoGFMPAcE",
        "outputId": "4a46929f-4708-4977-a62d-36407f0ad10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(ep, it)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-VTuAALP5b0"
      },
      "source": [
        "logits = net(seq, attn_masks)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGTuMIPHQD5U",
        "outputId": "b6ca6e11-9fc8-42d5-f358-c215ffa17bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "seq"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101, 1045, 2428,  ...,    0,    0,    0],\n",
              "        [ 101, 2070, 7309,  ...,    0,    0,    0],\n",
              "        [ 101, 2200, 5379,  ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 101, 2054, 1037,  ...,    0,    0,    0],\n",
              "        [ 101, 2200, 4895,  ...,    0,    0,    0],\n",
              "        [ 101, 2398, 2091,  ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jhIM1LFpqfT"
      },
      "source": [
        "# def trainFunc(net, loss_func, opti, train_loader, test_loader, config):\n",
        "#     best_acc = 0\n",
        "#     for ep in range(config[\"epochs\"]):\n",
        "#         for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "#             opti.zero_grad()\n",
        "#             #seq, attn_masks, labels = seq.cuda(args.gpu), attn_masks.cuda(args.gpu), labels.cuda(args.gpu)\n",
        "#             seq.to(config[\"device\"])\n",
        "#             attn_masks.to(config[\"device\"])\n",
        "#             labels.to(config[\"device\"])\n",
        "\n",
        "#             logits = net(seq, attn_masks)\n",
        "#             loss = loss_func(m(logits), labels)\n",
        "\n",
        "#             loss.backward()\n",
        "#             opti.step()\n",
        "#             print(\"Iteration: \", it+1)\n",
        "\n",
        "#             if (it + 1) % config[\"printEvery\"] == 0:\n",
        "#                 acc = get_accuracy(m(logits), labels)\n",
        "#                 if not os.path.exists(config[\"outputFolder\"]):\n",
        "#                     os.makedirs(config[\"outputFolder\"])\n",
        "\n",
        "#                 # Since a single epoch could take well over hours, we regularly save the model even during evaluation of training accuracy.\n",
        "#                 torch.save(net.state_dict(), os.path.join(config[\"outputFolder\"], config[\"outputFileName\"]))\n",
        "#                 print(\"Iteration {} of epoch {} complete. Loss : {} Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
        "\n",
        "#         # perform validation at the end of an epoch.\n",
        "#         val_acc, val_loss = evaluate(net, loss_func, val_loader, config)\n",
        "#         print(\" Validation Accuracy : {}, Validation Loss : {}\".format(val_acc, val_loss))\n",
        "#         if val_acc > best_acc:\n",
        "#             print(\"Best validation accuracy improved from {} to {}, saving model...\".format(best_acc, val_acc))\n",
        "#             best_acc = val_acc\n",
        "#             torch.save(net.state_dict(), os.path.join(config[\"outputFolder\"], config[\"outputFileName\"] + \"_valTested_\" + str(best_acc)))\n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv1BC8OYpqms",
        "outputId": "a0ab657a-29a1-47bb-bf57-65a975b80ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "# trainFunc(net, loss_func, opti, train_loader, val_loader, config)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-a83c308d14f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-150-1d521218d3ca>\u001b[0m in \u001b[0;36mtrainFunc\u001b[0;34m(net, loss_func, opti, train_loader, test_loader, config)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-e9d72dfed276>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq, attn_masks)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#Feeding the input to BERT model to obtain contextualized representations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mcont_reps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#Obtaining the representation of [CLS] head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 831\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m         )\n\u001b[1;32m    833\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #3 'index' in call to _th_index_select"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJTrgJe2pqtV"
      },
      "source": [
        "torch.load()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}