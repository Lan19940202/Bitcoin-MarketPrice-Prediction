{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lanwei02/Bitcoin-MarketPrice-Prediction/blob/master/sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYxGpCD-SKxI"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "pd.set_option('max_colwidth', 500)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xeIv89jbsl1",
        "outputId": "3e4f3682-5aab-456b-8e36-02a6d4346f4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "!pip install transformers bert torch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 26.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 20.6MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 11.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 9.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 8.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▏                            | 122kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143kB 8.5MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 163kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 184kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 194kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 215kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 225kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 235kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 245kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 256kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 276kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 286kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 296kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 307kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 317kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 327kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 337kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 348kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 358kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 368kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 378kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 389kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 399kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 409kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 419kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 430kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 440kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 450kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 460kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 471kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 481kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 491kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 501kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 512kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 522kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 532kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 542kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 552kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 563kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 573kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 583kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 593kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 604kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 614kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 624kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 634kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 645kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 655kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 665kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 675kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 686kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 696kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 706kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 716kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 727kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 737kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 747kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 757kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 768kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 778kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 788kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 798kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 808kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 819kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 829kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 839kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 849kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 860kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 870kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 880kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 890kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 901kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 911kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 921kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 931kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 942kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 952kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 962kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 972kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 983kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 993kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 8.5MB/s \n",
            "\u001b[?25hCollecting bert\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/e6/55ed98ef52b168a38192da1aff7265c640f214009790220664ee3b4cb52a/bert-2.2.0.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 21.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 25.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 44.9MB/s \n",
            "\u001b[?25hCollecting erlastic\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/30/f40d99fe35c38c2e0415b1e746c89569f2483e64ef65d054b9f0f382f234/erlastic-2.0.0.tar.gz\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: bert, sacremoses, erlastic\n",
            "  Building wheel for bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert: filename=bert-2.2.0-cp36-none-any.whl size=3756 sha256=e2245378f5cdc6e53633082be98d2958e3529c94c63db9dd91065d1289dc618c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/71/b7/941459453bd38e5d97a8c886361dee19325e9933c9cf88ad46\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=e110bf8ce1c10e149290299a96cb4abc39ca8298588cef3644e7c8b46dafad19\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for erlastic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for erlastic: filename=erlastic-2.0.0-cp36-none-any.whl size=6789 sha256=276b51317dd7faa6b90024ebac7cb1ec50bb6f0800d40f205e509aa5dfe2f100\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/62/46/93c713a5f061aeeb4f16eb6bf5ee798816e6ddda70faa78e69\n",
            "Successfully built bert sacremoses erlastic\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers, erlastic, bert\n",
            "Successfully installed bert-2.2.0 erlastic-2.0.0 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.2 transformers-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qubbusG0SNf-",
        "outputId": "c0df3f67-6c2e-4cb9-8414-ab8f8e8240ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Setup root directory\n",
        "GET_DATA_FROM_COLAB=True\n",
        "if GET_DATA_FROM_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive', force_remount=True)\n",
        "  root_path = '/content/gdrive/My Drive/Geekon2020' \n",
        "else: # Local machine\n",
        "    root_path ='' # e.g., root_path = '/Users/shxu/Documents/hack2020/'\n",
        "os.chdir(root_path)\n",
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Geekon2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u55mFLxmTmvd"
      },
      "source": [
        "senti_data = pd.read_csv('sentiment_hbw.csv',\n",
        "                         names = ['deal_uuid', 'permalink', 'grt_l1_cat_name', 'grt_l2_cat_name', 'grt_l3_cat_name', 'grt_l4_cat_name',\n",
        "                     'pds_cat_name', 'review', 'dwh_updated_at', 'int_value', 'sentiment_type', 'sentiment_score','user_id', 'client_platform'],\n",
        "                         delimiter='\\t', index_col=False,\n",
        "                         na_values = ['NA', 'N/A', '\\\\N'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KkaiDDIUEyS",
        "outputId": "7ec5444a-2553-4a69-c8ed-acd0b566b415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "senti_data.head(2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>deal_uuid</th>\n",
              "      <th>permalink</th>\n",
              "      <th>grt_l1_cat_name</th>\n",
              "      <th>grt_l2_cat_name</th>\n",
              "      <th>grt_l3_cat_name</th>\n",
              "      <th>grt_l4_cat_name</th>\n",
              "      <th>pds_cat_name</th>\n",
              "      <th>review</th>\n",
              "      <th>dwh_updated_at</th>\n",
              "      <th>int_value</th>\n",
              "      <th>sentiment_type</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>user_id</th>\n",
              "      <th>client_platform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77080685-4f91-4af2-ada2-e49703fcf6c4</td>\n",
              "      <td>pure-bliss-beauty</td>\n",
              "      <td>L1 - Local</td>\n",
              "      <td>L2 - Health / Beauty / Wellness</td>\n",
              "      <td>L3 - Maintenance</td>\n",
              "      <td>L4 - Eyelash &amp; Eyebrow Extensions</td>\n",
              "      <td>Eyelash Extensions</td>\n",
              "      <td>Crystal did an amazing job on my lashes. I love them!</td>\n",
              "      <td>2020-02-20 00:24:52.000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.70445</td>\n",
              "      <td>12c412d0-9244-11e6-8ccc-002590980646</td>\n",
              "      <td>ios</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>77080685-4f91-4af2-ada2-e49703fcf6c4</td>\n",
              "      <td>pure-bliss-beauty</td>\n",
              "      <td>L1 - Local</td>\n",
              "      <td>L2 - Health / Beauty / Wellness</td>\n",
              "      <td>L3 - Maintenance</td>\n",
              "      <td>L4 - Eyelash &amp; Eyebrow Extensions</td>\n",
              "      <td>Eyelash Extensions</td>\n",
              "      <td>This was a gift for my girlfriend and she absolutely loved it. Crystal did an amazing job on her eye lash extensions. Highly recommend this as she was very personable and professional.</td>\n",
              "      <td>2020-01-31 00:27:04.000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.81275</td>\n",
              "      <td>bc2f5190-a4e2-11e5-a3f9-002590980808</td>\n",
              "      <td>ios</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              deal_uuid  ... client_platform\n",
              "0  77080685-4f91-4af2-ada2-e49703fcf6c4  ...             ios\n",
              "1  77080685-4f91-4af2-ada2-e49703fcf6c4  ...             ios\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83LqwPLpWMCD"
      },
      "source": [
        "## *PreProcessing*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iShONghOWOU7"
      },
      "source": [
        "def preprocessing(data):\n",
        "\n",
        "  # Rename\n",
        "  data.rename(columns = {'int_value': 'star_rating', 'dwh_updated_at': 'update_timestamp'}, inplace = True)\n",
        "  \n",
        "  # Drop NULL Label\n",
        "  data = data[~data['star_rating'].isna()]\n",
        "\n",
        "  # Drop 0 star rating deals\n",
        "  data = data[data['star_rating']>0]\n",
        "\n",
        "  # Correct data type\n",
        "  data['update_timestamp'] = pd.to_datetime(data['update_timestamp'])\n",
        "  data['star_rating'] = data['star_rating'].astype(object)\n",
        "\n",
        "  # Impute NULL review with empty string\n",
        "  data['review'].fillna('', inplace = True)\n",
        "\n",
        "\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "senti_data_c = senti_data.copy()\n",
        "senti_data_c = preprocessing(senti_data_c)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQWrrCDFdjZC",
        "outputId": "bffff2cd-413e-4e08-cbb6-9cc8dff83014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "senti_data_c[senti_data_c['sentiment_type'].isnull()]['star_rating'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0    972\n",
              "4.0     94\n",
              "3.0     30\n",
              "1.0     26\n",
              "2.0     14\n",
              "Name: star_rating, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-tDNHxrdQ2Y",
        "outputId": "1c8642d9-0fcc-4cf0-f8bd-fdaf406c3963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "senti_data_c[senti_data_c['sentiment_type'].isnull()]['review'].unique()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' ', '\\\\n', '\\\\n\\\\n',\n",
              "       'My partner stated that the lady had a rough hand and also forced her to pay $10 for each treatment.',\n",
              "       '\\\\n\\\\n\\\\n', '  ', ' \\\\n', '     ',\n",
              "       'Ligia is excellent and very nice!\\\\nI will definitely visit her again.',\n",
              "       '\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n',\n",
              "       'She is professional.  Excellent job to my hair cut and color.  Love it.',\n",
              "       'Martha is amazing! The girls are so sweet and accommodating. The prices are so good here.',\n",
              "       '\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n',\n",
              "       'Elise is amazing!  Truly the best massage I have had in over 15 years!',\n",
              "       'Had an amazing experience here. No wait and Yvonne took her time and made sure I was satisfied. They also were very clean and sanitized everything along with following all COVID protocol. Would recommend this place to all my friends.',\n",
              "       '   \\\\n', '\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n', ' \\\\n\\\\n',\n",
              "       '\\\\n \\\\n\\\\n\\\\n', 'It was amazing, and much needed . Thanks'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qZDgwNeavB5"
      },
      "source": [
        "# senti_data_c['sentiment_type'].unique()[3]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f09b4qcOk_0s"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nst3MOh8WrRd"
      },
      "source": [
        "acc_df = pd.DataFrame(senti_data_c[['star_rating', 'sentiment_type']].value_counts()).rename(columns={0: 'count'}).reset_index()\n",
        "acc_df['pct'] = acc_df['count']/acc_df['count'].sum()\n",
        "acc_df['star_rating_sentiment'] = acc_df['star_rating'].map(lambda x: 'positive' if x >=4 else ('negative' if x <= 2 else 'neutral'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GRaK1CbhNQc",
        "outputId": "51b7e4ec-f44c-42cd-df6c-17636179f7f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "acc_df.sort_values(by=['star_rating_sentiment', 'sentiment_type'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>star_rating</th>\n",
              "      <th>sentiment_type</th>\n",
              "      <th>count</th>\n",
              "      <th>pct</th>\n",
              "      <th>star_rating_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>negative</td>\n",
              "      <td>5815</td>\n",
              "      <td>0.011931</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2.0</td>\n",
              "      <td>negative</td>\n",
              "      <td>1627</td>\n",
              "      <td>0.003338</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>1806</td>\n",
              "      <td>0.003706</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>1031</td>\n",
              "      <td>0.002115</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>19847</td>\n",
              "      <td>0.040722</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>7353</td>\n",
              "      <td>0.015087</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.0</td>\n",
              "      <td>negative</td>\n",
              "      <td>1302</td>\n",
              "      <td>0.002671</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3.0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>2615</td>\n",
              "      <td>0.005366</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>8974</td>\n",
              "      <td>0.018413</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5.0</td>\n",
              "      <td>negative</td>\n",
              "      <td>1396</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4.0</td>\n",
              "      <td>negative</td>\n",
              "      <td>509</td>\n",
              "      <td>0.001044</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>328980</td>\n",
              "      <td>0.675007</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>15700</td>\n",
              "      <td>0.032214</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>80528</td>\n",
              "      <td>0.165229</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>9889</td>\n",
              "      <td>0.020290</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    star_rating sentiment_type   count       pct star_rating_sentiment\n",
              "7           1.0       negative    5815  0.011931              negative\n",
              "10          2.0       negative    1627  0.003338              negative\n",
              "9           1.0       positive    1806  0.003706              negative\n",
              "13          2.0       positive    1031  0.002115              negative\n",
              "2           1.0        unknown   19847  0.040722              negative\n",
              "6           2.0        unknown    7353  0.015087              negative\n",
              "12          3.0       negative    1302  0.002671               neutral\n",
              "15          3.0        neutral       1  0.000002               neutral\n",
              "8           3.0       positive    2615  0.005366               neutral\n",
              "5           3.0        unknown    8974  0.018413               neutral\n",
              "11          5.0       negative    1396  0.002864              positive\n",
              "14          4.0       negative     509  0.001044              positive\n",
              "0           5.0       positive  328980  0.675007              positive\n",
              "3           4.0       positive   15700  0.032214              positive\n",
              "1           5.0        unknown   80528  0.165229              positive\n",
              "4           4.0        unknown    9889  0.020290              positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp0vkehRhcZU",
        "outputId": "1cd3a943-927b-4483-90a9-902ae0bc662f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "acc_df[acc_df['sentiment_type'] == acc_df['star_rating_sentiment']]['pct'].sum()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.722491808122321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuWdEbqpjvvN"
      },
      "source": [
        "# acc_df.to_csv('prevous_accuracy.csv')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWS43nEhj-vl"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZKufLAdvKaK"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPKbnK77mtWV"
      },
      "source": [
        "### Fine-Tuning BERT for Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-sHZXkivLze"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = senti_data_c['review'].values\n",
        "y = senti_data_c['star_rating'].values\n",
        "\n",
        "# 70% train, 20% validation, 10% test\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=2020, stratify = y)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HRMtARQvR9S"
      },
      "source": [
        "X = X_val\n",
        "y = y_val\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=0.333, random_state=2020, stratify = y)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHMkx9OfYwlX"
      },
      "source": [
        "df_train = pd.DataFrame({'review': X_train, 'star_rating': y_train}, columns=['review', 'star_rating'])\n",
        "df_val = pd.DataFrame({'review': X_val, 'star_rating': y_val}, columns=['review', 'star_rating'])\n",
        "df_test = pd.DataFrame({'review': X_test, 'star_rating': y_test}, columns=['review', 'star_rating'])"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm9rIkuZvRVg"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "import torch"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xN3J7CqCjan"
      },
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDsvFR3xvREx"
      },
      "source": [
        "# Use BERT tokenizer since it needs to be able to match the tokens to the pre trained words.\n",
        "# tokens = tokenizer.tokenize(X_train[0])"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCxWnQ0dvQNR"
      },
      "source": [
        "# print(tokens)\n",
        "# print(len(tokens))"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcqUCXoVvLjS"
      },
      "source": [
        "# BERT inputs typically start with a '[CLS]' tag and end with a '[SEP]' tag. For\n",
        "# tokens = ['[CLS]'] + tokens + ['[SEP]']"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSNzMrefvWOk"
      },
      "source": [
        "# maxlen = 400"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50Iz4bjYvWRu"
      },
      "source": [
        "# if len(tokens) < maxlen:\n",
        "#   # Add the ['PAD'] token\n",
        "#   tokens = tokens + ['[PAD]' for item in range(maxlen-len(tokens))]\n",
        "# else:\n",
        "#   # Truncate the tokens at maxLen - 1 and add a '[SEP]' tag.\n",
        "#   tokens = tokens[:self.maxlen-1] + ['[SEP]']  "
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2FUGEHhvWWi"
      },
      "source": [
        "# BERT tokenizer converts the string tokens to their respective IDs.\n",
        "# token_ids = tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxAsxNHn3dk2"
      },
      "source": [
        "# Converting to pytorch tensors.\n",
        "# tokens_ids_tensor = torch.tensor(token_ids)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeL0gBw6v_j3"
      },
      "source": [
        "# Masks place a 1 if token != PAD else a 0.\n",
        "# attn_mask = (tokens_ids_tensor != 0).long()"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsTux81Gv_mA"
      },
      "source": [
        "# attn_mask"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vCKMUbO-iz8"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su5JFIXqac51"
      },
      "source": [
        "config = {\n",
        "    \"splitRatio\" : 0.8,\n",
        "    # \"maxLength\" : 100,\n",
        "    \"maxLength\" : 400,\n",
        "    \"printEvery\" : 5,\n",
        "    \"outputFolder\" : \"Models\",\n",
        "    \"outputFileName\" : \"AmazonReviewClassifier.dat\",\n",
        "    \"threads\" : 4,\n",
        "    \"batchSize\" : 64,\n",
        "    \"validationFraction\" : 0.0005,\n",
        "    \"epochs\" : 5,\n",
        "    \"forceCPU\" : False\n",
        "    }"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAMUSrQ4mUaC"
      },
      "source": [
        "df = pd.concat([df_train, df_val])"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOTn5GQwfHtZ",
        "outputId": "e851506e-784a-4173-bd73-ddd2536a40f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_classes = df['star_rating'].nunique()\n",
        "print(\"Number of Target Output Classes:\", num_classes)\n",
        "totalDatasetSize = len(df)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Target Output Classes: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtHyCHzYozdz"
      },
      "source": [
        "# Group by the column Score. This helps you get distribution of the Review Scores.\n",
        "symbols = df.groupby('star_rating')"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbIaGoNeo7RM"
      },
      "source": [
        "scores_dist = []\n",
        "for i in range(num_classes):\n",
        "  scores_dist.append(len(symbols.groups[i+1])/totalDatasetSize)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgVdWOwBpIul",
        "outputId": "ecfc351b-8e88-4aaa-acf8-078c7162306c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "scores_dist"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05628078761718057,\n",
              " 0.02052280387349729,\n",
              " 0.026451765497855384,\n",
              " 0.05361537027013504,\n",
              " 0.8431292727413318]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGwl80FOeSQ9",
        "outputId": "a999852a-2851-4de8-e5dd-28e63afbad9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Set GPU for Training\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    config[\"device\"] = device\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZHYIukYefaG",
        "outputId": "790eee15-eec4-4af2-950d-27974540dc7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-tG5Xk2vWYy"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, df, maxlen):\n",
        "        self.df = df\n",
        "        # self.df_x = df_x\n",
        "        # self.df_y = df_y\n",
        "        # A reset reindexes from 1 to len(df), the shuffled df frames are sparse.\n",
        "        # self.df.reset_index(drop=True, inplace=True)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return(len(self.df))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        review = self.df.loc[index, 'review']\n",
        "        # review = self.df_x.loc[index]\n",
        "\n",
        "        # Classes start from 0.\n",
        "        # label = int(self.df.loc[index, 'Score']) - 1\n",
        "        # label = int(self.df_y.loc[index]) - 1\n",
        "        label = int(self.df.loc[index, 'star_rating']) - 1\n",
        "\n",
        "        # Use BERT tokenizer since it needs to be able to match the tokens to the pre trained words.\n",
        "        tokens = self.tokenizer.tokenize(review)\n",
        "\n",
        "        # BERT inputs typically start with a '[CLS]' tag and end with a '[SEP]' tag. For\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "\n",
        "        if len(tokens) < self.maxlen:\n",
        "            # Add the ['PAD'] token\n",
        "            tokens = tokens + ['[PAD]' for item in range(self.maxlen-len(tokens))]\n",
        "        else:\n",
        "            # Truncate the tokens at maxLen - 1 and add a '[SEP]' tag.\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]']\n",
        "\n",
        "        # BERT tokenizer converts the string tokens to their respective IDs.\n",
        "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # Converting to pytorch tensors.\n",
        "        tokens_ids_tensor = torch.tensor(token_ids)\n",
        "\n",
        "        # Masks place a 1 if token != PAD else a 0.\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHOiGAJm8AzB"
      },
      "source": [
        "train_set = ReviewsDataset(df_train, maxlen = config['maxLength'])\n",
        "val_set = ReviewsDataset(df_val, maxlen = config['maxLength'])\n",
        "test_set = ReviewsDataset(df_test, maxlen = config['maxLength'])"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qd20lFKUBZH"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBS8hurk-pxX"
      },
      "source": [
        "train_loader = DataLoader(train_set, batch_size = config[\"batchSize\"], num_workers = config[\"threads\"])\n",
        "val_loader = DataLoader(val_set, batch_size = config[\"batchSize\"], num_workers = config[\"threads\"])\n",
        "test_loader = DataLoader(test_set, batch_size = config[\"batchSize\"], num_workers = config[\"threads\"])"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiGnvjlre4qJ"
      },
      "source": [
        "### Define the Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QQnXSSn-p68"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import  BertModel, BertTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, num_classes, device, freeze_bert = True):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.device = device\n",
        "\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        self.cls_layer = nn.Linear(768, num_classes)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "        '''\n",
        "\n",
        "        #Feeding the input to BERT model to obtain contextualized representations\n",
        "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
        "\n",
        "        #Obtaining the representation of [CLS] head\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "\n",
        "        #Feeding cls_rep to the classifier layer\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits.to(self.device)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgBkK2mKghgj",
        "outputId": "6a5c5f8a-8cf6-4844-d95e-df0feb3fa221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config[\"device\"]"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugs6dEUR-p90"
      },
      "source": [
        "# We are unfreezing the BERT layers so as to be able to fine tune and save a new BERT model that is specific to the Sizeable food reviews dataset.\n",
        "net = SentimentClassifier(num_classes, config[\"device\"], freeze_bert=False)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95QcoMhu-p_m"
      },
      "source": [
        "net.to(config[\"device\"])\n",
        "weights = torch.tensor(scores_dist).to(config[\"device\"])"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYfTy3IF-qCV"
      },
      "source": [
        "# Setting the Loss function and Optimizer.\n",
        "loss_func = nn.NLLLoss(weight=weights)\n",
        "opti = optim.Adam(net.parameters(), lr = 2e-5)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y8H_b4k-qET"
      },
      "source": [
        "m = nn.LogSoftmax(dim=1)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YulVQNs4qCph"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jhIM1LFpqfT"
      },
      "source": [
        "def trainFunc(net, loss_func, opti, train_loader, test_loader, config):\n",
        "    best_acc = 0\n",
        "    for ep in range(config[\"epochs\"]):\n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            opti.zero_grad()\n",
        "            #seq, attn_masks, labels = seq.cuda(args.gpu), attn_masks.cuda(args.gpu), labels.cuda(args.gpu)\n",
        "            seq.to(config[\"device\"])\n",
        "            attn_masks.to(config[\"device\"])\n",
        "            labels.to(config[\"device\"])\n",
        "\n",
        "            logits = net(seq, attn_masks)\n",
        "            loss = loss_func(m(logits), labels)\n",
        "\n",
        "            loss.backward()\n",
        "            opti.step()\n",
        "            print(\"Iteration: \", it+1)\n",
        "\n",
        "            if (it + 1) % config[\"printEvery\"] == 0:\n",
        "                acc = get_accuracy(m(logits), labels)\n",
        "                if not os.path.exists(config[\"outputFolder\"]):\n",
        "                    os.makedirs(config[\"outputFolder\"])\n",
        "\n",
        "                # Since a single epoch could take well over hours, we regularly save the model even during evaluation of training accuracy.\n",
        "                torch.save(net.state_dict(), os.path.join(config[\"outputFolder\"], config[\"outputFileName\"]))\n",
        "                print(\"Iteration {} of epoch {} complete. Loss : {} Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
        "\n",
        "        # perform validation at the end of an epoch.\n",
        "        val_acc, val_loss = evaluate(net, loss_func, val_loader, config)\n",
        "        print(\" Validation Accuracy : {}, Validation Loss : {}\".format(val_acc, val_loss))\n",
        "        if val_acc > best_acc:\n",
        "            print(\"Best validation accuracy improved from {} to {}, saving model...\".format(best_acc, val_acc))\n",
        "            best_acc = val_acc\n",
        "            torch.save(net.state_dict(), os.path.join(config[\"outputFolder\"], config[\"outputFileName\"] + \"_valTested_\" + str(best_acc)))\n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv1BC8OYpqms",
        "outputId": "a0ab657a-29a1-47bb-bf57-65a975b80ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "trainFunc(net, loss_func, opti, train_loader, val_loader, config)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-a83c308d14f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-150-1d521218d3ca>\u001b[0m in \u001b[0;36mtrainFunc\u001b[0;34m(net, loss_func, opti, train_loader, test_loader, config)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-e9d72dfed276>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq, attn_masks)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#Feeding the input to BERT model to obtain contextualized representations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mcont_reps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#Obtaining the representation of [CLS] head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 831\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m         )\n\u001b[1;32m    833\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #3 'index' in call to _th_index_select"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJTrgJe2pqtV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}